{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 518 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n",
      "這是肯德基\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "subcontractor='五一八外包網'\n",
    "if subcontractor=='五一八外包網':\n",
    "    print type(subcontractor)\n",
    "    m=re.match('五一八外包網', subcontractor)\n",
    "    if m:\n",
    "        print '這是肯德基'\n",
    "            \n",
    "    else:  \n",
    "        print \"這不是肯德基\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-64eca5a94921>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0msoup1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtotal_page\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msoup1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.pagecountnum span'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mtotal_page\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mpages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_page\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "import shutil\n",
    "import requests \n",
    "from bs4 import BeautifulSoup as BS\n",
    "from math import ceil\n",
    "#資訊軟體‧MIS網管\n",
    "#first_url='http://www.518.com.tw/job-index.html?ad=&aa=&ab=2032001%2C2032002%2C&ac=&am=1&i=1&ae=&af=&ag=&ah=&ai=&aj=&ak=&ak_min=&ak_max=&al=&an=&ao=&ap=&aq=&ar=&as='\n",
    "first_url=\"http://www.518.com.tw/job-index-P-1.html?i=1&am=1&ab=2032001,2032002,\"\n",
    "res=requests.get(first_url)\n",
    "soup1=BS(res.text)\n",
    "total_page=soup1.select('.pagecountnum span')[0]\n",
    "#print total_page\n",
    "pages=int(total_page.text.split(\" \")[2])+1\n",
    "#page=int(total_page.text.replace(\",\",\"\"))\n",
    "#count_page=int(ceil(float(page/27.0)))\n",
    "\n",
    "for i in xrange(1,2):\n",
    "    job_url=\"http://www.518.com.tw/job-index-P-{}.html?i=1&am=1&ab=2032001,2032002,\".format(i)\n",
    "    res2=requests.get(job_url)\n",
    "    soup2=BS(res2.text)\n",
    "    soup2.decoding='utf-8'\n",
    "    divs2=soup2.select('#listContent ul')\n",
    "    j=1\n",
    "    #while(j<51):\n",
    "    #j=j+1\n",
    "    k=0\n",
    "    #print len(divs2)\n",
    "    for ul in divs2[0:-3]:\n",
    "        k=k+1\n",
    "        subcontractor1=ul.select('.company')[0]\n",
    "        subcontractor=subcontractor1.text.encode('utf8')\n",
    "        #print subcontractor #company\n",
    "        #if subcontractor=='五一八外包網':\n",
    "        #print type(subcontractor)\n",
    "        #m=re.match('五一八外包網', subcontractor)\n",
    "        #if m:\n",
    "                #print rrrrrr\n",
    "                #continue     \n",
    "        #else:       \n",
    "        each_job_url=ul.select('.title a')[0]['href']\n",
    "        #print each_job_url\n",
    "        res3=requests.get(each_job_url)\n",
    "        soup3=BS(res3.text)#已抓到每一個求職的說明頁面\n",
    "        #currenttime=datetime.now()\n",
    "        #public_time=currenttime.strftime(\"%Y-%m-%d\") #公告日期\n",
    "        all_container=soup3.select('#container')[0]\n",
    "        #print all_container #右側廣告也包含\n",
    "        position=soup3.select('#container h1')[0]\n",
    "        short_infor=soup3.select('.company-info')[0]\n",
    "        long_infor=soup3.select('#content')[0]\n",
    "        #print long_infor\n",
    "        #print short_infor\n",
    "        with open('C:/Users/BIG DATA/pythonETL/518_job/518_job_page_{}_{}.txt'.format(i,k) , 'w') as f:\n",
    "                    f.write(position.text.encode('utf-8') +'\\n'+short_infor.text.encode('utf-8')+'\\n'+long_infor.text.encode('utf-8'))\n",
    "        time.sleep(2.5)\n",
    "        #print (position.text +'\\n'+short_infor.text+'\\n'+long_infor.text)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 518單頁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import requests \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from datetime import date,datetime\n",
    "#資訊軟體‧MIS網管\n",
    "each_job_url='http://www.518.com.tw/101_%E7%B6%B2%E7%AB%99%E5%B7%A5%E7%A8%8B%E5%B8%AB-%E6%96%B0%E5%8C%97%E5%B8%82-%E4%B8%89%E9%87%8D%E5%8D%80-job-660380.html'\n",
    "res=requests.get(each_job_url)\n",
    "soup2=BS(res.text)\n",
    "#print soup2.text\n",
    "#print position.text\n",
    "#company=soup2.select('.company-info a')[0]\n",
    "#print company.text\n",
    "#industry1=soup2.select('.company-info p')[1]\n",
    "#industry=industry1.select('a')[0]['title'][0:]\n",
    "#print industry\n",
    "currenttime=datetime.now()\n",
    "public_time=currenttime.strftime(\"%Y-%m-%d\") #公告日期\n",
    "all_container=soup2.select('#container')[0]\n",
    "#print all_container #右側廣告也包含\n",
    "position=soup2.select('#container h1')[0]\n",
    "short_infor=soup2.select('.company-info')[0]\n",
    "long_infor=soup2.select('#content')[0]\n",
    "#print long_infor\n",
    "#print short_infor\n",
    "with open('C:/Users/BIG DATA/pythonETL/518_job/518_job_page_{}.txt'.format(1) , 'w') as f:\n",
    "            f.write(position.text.encode('utf-8') +'\\n'+short_infor.text.encode('utf-8')+'\\n'+long_infor.text.encode('utf-8'))\n",
    "#print (position.text +'\\n'+short_infor.text+'\\n'+long_infor.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
